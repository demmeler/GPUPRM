\documentclass{scrartcl} 
%\documentclass[a4paper]{article}
%\usepackage{a4wide}

\usepackage[ngerman,english]{babel}
 \usepackage[T1]{fontenc}
\usepackage{lmodern}
\usepackage[applemac]{inputenc}

\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{amstext}
\usepackage{amsthm}

\usepackage{fancyhdr}
\usepackage{paralist}

\usepackage{mathtools}


\usepackage{hyperref}


\usepackage{graphicx}


\usepackage{wrapfig}


% PSEUDOCODE

\usepackage[ruled]{algorithm2e}


% C++ CODE

\usepackage{listings}
\usepackage{xcolor}
\definecolor{lbcolor}{rgb}{0.9,0.9,0.9}

\lstdefinestyle{customc}{
  belowcaptionskip=1\baselineskip,
  breaklines=true,
  %frame=LR,
  %xleftmargin=\parindent,
  language=C,
  showstringspaces=false,
  basicstyle=\footnotesize\ttfamily,
  keywordstyle=\bfseries\color{green!40!black},
  commentstyle=\itshape\color{purple!40!black},
  identifierstyle=\color{blue},
  stringstyle=\color{orange},
}

\lstdefinestyle{customcpp}{
	backgroundcolor=\color{lbcolor},
    	tabsize=4,
    	language=[GNU]C++,
        basicstyle=\tiny,%{\scriptsize},
        upquote=true,
        %aboveskip={1.5\baselineskip},
        columns=fixed,
        showstringspaces=false,
        extendedchars=false,
        breaklines=true,
        prebreak = \raisebox{0ex}[0ex][0ex]{\ensuremath{\hookleftarrow}},
        frame=single,
        numbers=left,
        showtabs=false,
        showspaces=false,
        showstringspaces=false,
        identifierstyle=\ttfamily,
        keywordstyle=\color[rgb]{0,0,1},
        commentstyle=\color[rgb]{0.026,0.112,0.095},
        stringstyle=\color[rgb]{0.627,0.126,0.941},
        numberstyle=\color[rgb]{0.205, 0.142, 0.73},
}

\lstset{escapechar=@,style=customcpp}


% TIKZ DIAGRAMS

\usepackage{tikz}
\usetikzlibrary{arrows}
\usetikzlibrary{positioning}

\tikzset{
    block/.style={
           rectangle,
           rounded corners,
           draw=black, very thick,
           minimum height=2em,
           inner sep=2pt,
           text centered,
           },
     block2/.style={
           %rectangle,
           %rounded corners,
           fill=black!20,
           %draw=black, very thick,
           minimum height=2em,
           inner sep=2pt,
           text centered,
           },
     frameless/.style={
           %rectangle,
           %rounded corners,
           %draw=black, very thick,
           minimum height=2em,
           inner sep=2pt,
           text centered,
           },
}

\usepackage{tikz-cd}
\tikzset{
  shift left/.style ={commutative diagrams/shift left={#1}},
  shift right/.style={commutative diagrams/shift right={#1}}
}



\DeclareMathOperator*{\esssup}{ess.sup}
\DeclareMathOperator*{\defgl}{\vcentcolon=}


%\pagestyle{fancy}
%\fancyhead[L]{Seminar \glqq Optimale Steuerung\grqq\\ Prof. Brokate, Prof. Kuttler} %Kopfzeile links
%\fancyhead[C]{} %zentrierte Kopfzeile
%\fancyhead[R]{10. Dezember 2013\\ Manuel Demmeler} %Kopfzeile rechts
\title{\vspace{-1.3cm} \textmd{\normalsize{High Performance Computing Project}}\\ Parallelization of the Probabilistic Roadmap Method with GPU Acceleration}
\date{}
\author{Manuel Demmeler}

%\thispagestyle{fancy}

\newcommand{\3}{ ^{3\times3} }
\newcommand{\R}{\mathbb{R}}
\newcommand{\N}{\mathbb{N}}
\newcommand{\M}{\mathbb{M}}
\newcommand{\Sym}{\mathbb{S}^3}
\newcommand{\Mpos}{\M_+^3}
\newcommand{\Orth}{\mathbb{O}^3}
\newcommand{\norm}[1]{\left\lVert#1\right\rVert}
\newcommand{\abs}[1]{\left |#1\right |}
\newcommand{\ub}{\bar{u}}
\newcommand{\yb}{\bar{y}}
\newcommand{\scprod}[2]{\langle#1 , #2 \rangle}

%\vspace{-3.4cm}


\begin{document}
\maketitle

\section{Motivation}
In trajectory optimization with obstacles, it is often necessary to provide feasible initial trajectories. 
For example in robot motion planning, where the dimensions of the underlying spaces are rather high, this can be expensive. A further problem is that because of the transformation from work into configuration space, the obstacles are often no longer given in a closed form. An efficient approximative approach is using probabilistic roadmaps (PRMs).

In this project, a parallelized version of the PRM method has been developed in general.
The robotics application then was implemented as an special case of this with GPU support.


\section{Introduction}
\subsection{Problem Statement and the Sequential PRM Method}\label{algintro}
\newtheorem*{defi}{Definition}
\newtheorem*{alg1}{Algorithm}


The abstract problem is to find a path on a d-dimensional space, which avoids intersecting obstacles. The obstacles are  given by an indicator function
\begin{equation*}
	I: \Omega \rightarrow \{0, 1\}
\end{equation*}
on the domain \( \Omega = [ q_{min,1}, q_{max,1} ] \times ... \times  [ q_{min,d}, q_{max,d} ] \subset \R^d  \) and the goal is to find a continuous way
\begin{equation*}
	\Gamma: [0,1] \rightarrow \Omega
\end{equation*}
between a given start and endpoint, \(\Gamma(0)=q_b,\ \Gamma(1)=q_e \), 
such that
\begin{equation*}
	I(\Gamma(s))=0 \text{\ f.a.\ } sÊ\in [0,1].
\end{equation*}
The probabilistic roadmap (PRM) approach grows a graph \(G=(V,E)\) form \(q_s\) and \(q_e\) by randomly sampling nodes \(v\in V\subset \Omega\).  Two nodes \(v,w \in V\) are connected, if they are near enough each other and the linear connection in between is free from obstacles. The algorithm terminates, when there is a path from \(q_s\) to \(q_e\) on G.
\begin{defi}
For two points \(q_1\) and \(q_2\) we define the connection with stepsize \(h>0\) as
	\begin{equation*}
		[q_1,q_2]_h \defgl \{ q = \lambda q_1+(1-\lambda) q_2\ |\ \lambda \in [0,1], \norm{q-q_1} \in \N_0 h \}.
	\end{equation*}
	We say, \(q_1\) and \(q_2\) are connected (with stepsize \(h>0\)) on the map \(\Omega\), if
	\(I(q)=0\) for all \(q \in [q_1, q_2]_h\).
\end{defi}

\begin{algorithm} 
	\caption{Probabilistic Roadmap in general}
	\KwData{ \(q_s, q_e\in \Omega, h>0, d_0>0\)}
	\KwResult{ \(q_s=q_1, ... ,q_n=q_e\in \Omega\), 
		such that all \(q_i\) and \(q_{i+1}\) are connected with stepsize \(h\)}
	Initialize graph \(G=(V,E)\) with \(V=\{q_s, q_e\}\) \\
	If \(q_s\) and \(q_e\) are connected, \(E \leftarrow\{ q_s, q_e\}\) \\
	\While{ there exists no path in G between \(q_s\) and \(q_e\)}{
		Sample \(q\in \Omega\) from a probability density  \(p(\ \cdot\ , G)\), resample until \(I(q)=0\) \\
		\For{ all nodes \(\tilde{q} \in V\), with \( \norm{q- \tilde q} \le d_0 \) }{
			\If { $q$ and $\tilde q$ connected with stepsize h} {
				\(E \leftarrow \{q, \tilde{q}\}\)
			}
		}
		\(V \leftarrow{q}\), if at least one edge was inserted \\
	}
	Determine the shortest path \(q_1, ... , q_n\in V\) on \(G\) from \(q_s\) to \(q_e\).
\end{algorithm}

The probability density \(p(\ \cdot\ ,G)\) (depending on the actual graph) can be for example first selecting randomly a node \(q_0 \in V\) and then sampling a new point \(q\) in the neighbourhood of \(q_0\). Theory about success probabilities and convergence results can be found in \cite{prmlec}, \cite{prm1} or \cite{prm2}.


\subsection{Application to Robotics}


\begin{figure}
    \centering
    \includegraphics[width=0.8\textwidth]{configspacetrafo.png}
    \caption{Example for an indicator function in robotics from \cite{prmlec}. 
    		The real obstacles on the left are transformed 
		into occupied areas of the configuration space on the right.}
    \label{fig:awesome_image}
\end{figure}

In the project, the PRM algorithm is used to find trajectories for a robot arm, which avoid self collisions and collisions with obstacles in the environment.
Such trajectories can be expressed as functions describing the joint variables changing over time, that means curves in the configuration space with dimension equal to the number of degrees of freedom of the robot.
With this association, the trajectory finding problem becomes a path finding problem in the configuration space exactly of the form stated in the previous chapter.
The real obstacles transform into obstacles in the configuration space, given by the indicator function, that returns for a given set of joints, if the configuration is feasible or a collision occurs.


\newpage
\subsection{Project Overview}

Like in the stated robotics example, in many cases the most costly operation of the PRM algorithm are the many evaluations of the indicator function \(I(q)\), 
which however can be done independently for every new \(q\).
Therefore $I(q)$ is implemented in a vectorized way as a function \((q_1, ... , q_P) \mapsto (I(q_1),...,I(q_P))\) by a CUDA kernel, where every thread computes one evaluation.
In the robotics case, this means, the direct kinematic and collision calculation are made on the GPU parallely for different joint angle configurations.
Although this will the only major application in the project, the PRM solver and the configuration space are implemented seperated from each other and connected by an interface to be free to simply add other applications. As an example and for testing, additionally a simple 2D configuration space is provided, 
whose indicator function is read from a black-and-white image.


\begin{center} 
\begin{tikzpicture}[auto]%node distance=0.5cm and 1.8cm]
	\node[block] (prm) {
		\begin{tabular}{c}
		\textbf{PRMSolver}\\
		generate nodes\\
		store graph
		\end{tabular}
	};
	\node [block, right=of prm] (config) {
		\begin{tabular}{c}
		\textbf{Configpace}\\
		indicator fct. \\
		interface
		\end{tabular}
	};
	\node [block, right=of config] (robo) {
		\begin{tabular}{c}
		\textbf{RobotConfigspace}\\
		robot kinematics\\
		collision detection
		\end{tabular}
	};
	\node [block, right=of robo] (gpu) {\textbf{GPU}};
	
	\path[-stealth,thick, shift left=1.0ex]	(prm) edge (config) ;
	\path[-stealth,thick, shift left=1.0ex]	(config) edge  (prm) ;
	\path[-stealth,thick, shift left=1.0ex]	(config) edge (robo);
	\path[-stealth,thick, shift left=1.0ex]	(robo) edge  (config);
	\path[-,thick]					(robo) edge (gpu);
\end{tikzpicture}
\end{center}


While the distribution of the indicator function to different CUDA threads is a first level of parallelization, 
a second level can be achieved by sampling and connecting several new nodes parallely. 
This is more difficult, because all new nodes have to be connected 
and the graph data has to be updated on all processes. 
For this, different approaches have been implemented, which are described in chapter \ref{solver}.

Before that, chapter \ref{indicator} gives more details about the robotics indicator function.

\section{Implementation of an Indicator Function for Robot Arms}\label{indicator}

In the project, the probabilistic roadmap algorithm is applied  to create collisionfree trajectories of a robot arm.
For a robot with given joint angles \(q_i\) one can calculate straightforwardly all positions and orientations  of the single parts of the robot.
For this, coordinate frames according to the Denavit-Hartenberg convention are used.
The coordinate frames of the single parts are described by transformation matrices 
$T_i \in R^{4x4}$, which transform points from the body frame frame into the world frame. They depend on the state $q=(q_1,...,q_d)$ of the robot and on the geometry of the joint angles given by the Denavit-Hartenberg parameters of the robot. 

The geometry of the robot parts is defined by a set of convex polytopes, each of them belonging to one of the robots coordinate frame. Applying the corresponding transformation $T_i$, its vertices can be transformed into the world frame. 
Environment obstacles are also defined by convex polytopes, in the world frame.

Now the movement of the robot can be described by a curve $q(t) \in \R^d$ in the configuration space. It is collisionfree, if at no time, any two polytopes of the robot intersect with each other or with the environment after being transformed into the world frame.
To apply the probabilistic roadmap algorithm, we express this by the indicator function

\begin{equation*}
	I(q)=
	\begin{cases}
		0,	& \text{ for no collision for all given pairs of polytopes } \\
		1,	& \text{ if at least one collision occurs }
	\end{cases}
\end{equation*}

It has to be noted that the trajectories \(q(t)\) the PRM algorithm generates are piecewise linear and therefore not differentiable. Hence, they have to be smoothed before the use on a robot. This is not part of the project. The task is only to generate feasible trajectories to be passed to an optimizer.

The indicator function is implemented in a vectorized way as an CUDA kernel, which means that, given set of states $q^1,..,q^M$, the indicator function is evaluated for each state by one CUDA thread. Therefore, the kinematics and collision algorithm are implemented as device code for the use in the kernel.

\subsection{Direct Kinematics}\label{dk}

The Denavit-Hartenberg (DH) convention is a method to describe the geometry of an robots joints, 
that is, how the transformations between the robots coordinate frames look like in dependancy of its joint values $q_1,...,q_d$.
For this it is assumed that each joint is either rotational, that means an rotation around a fixed axis, 
or prismatic, a translation along an axis.
The robot consists of $d+1$ bodies each of which has an body fixed coordinate frame $B_i$, which is described by a transformation matrix $T_i$ into the world frame.
For a robot with DH parameters $a_{i-1}, \alpha_{i-1}, d_i, \theta_i \in \R$, $i=1,...,d$, 
it is now defined, that the relative transformations $T_{i-1,i}=T_{i-1}^{-1} T_{i}$ between two bodies are
\begin{equation}
	T_{i-1,i} = R_z(\theta_i) T_z(d_i) R_x(\alpha_{i-1}) R_x(a_{i-1})
\end{equation}
where $R_x, R_z$ are rotations and $T_x, T_z$ translations around the $x$ and $z$ axes.
From this follows, that from given DH parameters all transformations are determined.
The other way round, one can show, that by an proper choice of the body frames, every robot with rotational or prismatic joints can be described by a set of DH parameters.
For the exact calculations, see \cite{robodyn}.


\subsection{2D and 3D Geometry Library}

For the CUDA implementation of the kinematics and later the collision algorithm, a geometry library was written, based on the CUDA datatypes float2 for 2D vectors and float4 for 3D vectors.
To guarantee aligned access on the GPU, float4 is used instead of float3. Furthermore, as the geometric calculations made here are numerically not very critical, the usage of double precision has turned out to be not necessary.
The library contains hybrid host and device inline functions for common vector operations such as
\begin{lstlisting}
__host__ __device__ inline float4& operator += (float4& u, const float4& v);
__host__ __device__ inline float4& operator *=  (float4& u, const float f);
__host__ __device__ inline float4& add(const float4& u, const float4& v, float4& w);
\end{lstlisting}
Operators like $+$ or $*$ are not overloaded to prevent unnecessary temporary variables.

Transformation matrices are implemented as float4 arrays with inline functions for common matrix operations. Again operators with temporaries were avoided, wherever possible.
\begin{lstlisting}
class trafo4{
  public:
    float4 col[4];
    __host__ __device__ trafo4(){}
    __host__ __device__ trafo4(float a, float alpha, float q, float d);
    __host__ __device__ inline float4& apply(float4& u) const;
    __host__ __device__ inline float4& apply(const float4& u, float4& Tu) const;
    .
    .
    .
}
\end{lstlisting}

\subsection{Polytopes}

To calculate the intersection between two convex polytopes, the Chung-Wang algorithm only needs their vertices 
and the data which vertices are connected by an edge. 
For this the adjacency matrix of the edge graph is stored compactly in the crs format.
\begin{lstlisting}
struct polytope4{
    float4* vertices;	//length n
    int n;
    //edges
    int* dsp;	//length n
    int* cnt;	//length n
    int* dest;	//length m
    int m;
};
\end{lstlisting}
It means, that for $i=0,...,n-1$ the vertices $dest[dsp[i]],...,dest[dsp[i]+cnt[i]-1]$ are the ones connected with vertex $i$ by an edge.
The polytopes used in this projects are given by the user as convex hull of a list of vertices. However, to determine the edge graph only from the vertices is a nontrivial task, which is done by Matlab here using provided high level functions.


\subsection{Chung-Wang Collision Algorithm}

To check if two polytopes collide an algorithm by Chung and Wang is used here. It uses the separating vector theorem and tries to find a seperating vector by iterative search. Furthermore, a subalgorithm determines in each iteration from the candidate history, if it is still theoretically possible to find a seperating vector. If not, it is returned a collision. If on the other side a seperating vector is found, the algorithm can return no collision.
For detailed informations see \cite{chung} and \cite{ericson}, pp. 410-412.
The method is implemented as device code for the use on GPU kernels.
\begin{lstlisting}
__host__ __device__ int seperating_vector_algorithm(const polytope4& P, const polytope4& Q, 
													const trafo4& tp, const trafo4& tq);
\end{lstlisting}
In our application, the polytopes are mostly parts of the robot, which are given in a body frame and have to be transformed into world frame according to section \ref{dk} first.
However, from the structure of the Chung-Wang algorithm drops out that mostly only a small part of the polytopes vertices are needed for the computations. Therefore it would be rather time wasting to transform all vertices before passing to the algorithm. To avoid this, all polytopes are passed in their body frames together with their transformations and the algorithm transforms vertices at the time they occur in calculations.





\subsection{Robot Kernel}

The robot configuration space is implemented in the form
\begin{lstlisting}
template<int ndof>
class RobotConfigspace : public Configspace<ndof>
{
public:
  RobotConfigspace(const Robot<ndof>* robot_,
                   const polytope *polys_,
                   const int* sys_,
                   const int N_,
                   const int *from_, const int *to_,
                   const int M_,
                   const float* mins_, const float* maxs_, const float dq_,
                   const int nbuf_);
  int init(const int ressource_rank=0, const int ressource_size=1);
  int indicator2(const float* qs, const float* qe, int *res, const int N, const int offset);
  .
  .
  .
private:
  const Robot<ndof>* robot; //host
  Robot<ndof>* robotdev;    //GPU
  collision4::polytope4data* polydata;            //data on host
  collision4::polytope4data* polydatadev;         //pointer to GPU obj
  .
  .
  .
}
\end{lstlisting}
\begin{lstlisting}
__global__ void kernel_indicator2(const Robot<ndof>* robot,
                                  const collision4::polytope4data* polydata,
                                  const float* qs, int offsets,
                                  const float* qe, int offsete,
                                  int* res,
                                  const int* testpos, const int* testnum,
                                  int N, int numthreads);
\end{lstlisting}
where the constant geometry and robot data is passed once at the beginning and copied to the GPU by an init function.
The indicator function gets as input a list of border points $q_{start}^j, q_{end}^j, j=0,...,N$ and checks now for each pair, if on the line in between the indicator function is always 0.
\begin{equation}
	res[j]=\begin{cases}
		0	&\text{if $I(q)=0$ f.a. $q \in \left[qs[j], qe[j]\right]_{\Delta q}$} \\
		1	&else
	\end{cases}
\end{equation}
The border points are stored in structures of arrays.
\begin{equation}
\begin{aligned}
	q_{start}^j &= \left(qs[j],qs[j+\text{offset}],...,qs[j+(d-1)*\text{offset}]\right)^T\\
	q_{end}^j &= \left(qe[j],qe[j+\text{offset}],...,qe[j+(d-1)*\text{offset}]\right)^T
\end{aligned}
\end{equation}

As the PRMSolver only needs to know, which node points can be connected by a line, and not, which points on the line exactly are free, this version delivers exactly the minimal necessary information. Furthermore it saves CPU and communication time, because the intermediate points on the lines can be directly computed by the GPU threads and do not need to be exchanged.

Algorithms \ref{host} and \ref{kernel} two show in pseudo code, how the work is split between host and device.


\begin{algorithm}\label{host}
	\KwData{qs, qe, N, offset}
	\KwResult{res}
	compute distances $d_j = \abs{q_{end}^j - q_{start}^j}$ \;
	testnum[j] = $d_j/{\Delta q}$: number of threads for each line \;
	testpos[j] = thread displacements \;
	reset res \;
	call kernel \;
	\caption{Host indicator function}
\end{algorithm}

\begin{algorithm}\label{kernel}
	\KwData{arrays qs, qe, testpos, testnum and threadindex}
	\KwResult{res}
	compute associated edge number $j$, defined by $testpos[j] \leq threadindex \le testpos[j]+testnum[j]$ \;
	$c = (threadindex - testpos[j]) / (testnum[k]-1) $ \;
	$q=c q_{start}^j + (1-c) q_{end}^j $ \;
	calculate robot kinematics $T_0(q), ..., T_d(q) $\;
	$res_{tmp} = 0; $ \;
	\For{all registered pairs pairs of polytopes $P, Q$}{
		$res_{tmp}=seperating\_vector\_algorithm(P, T_{i_P}, Q, T_{i_Q})$ \;
		\If{$res_{tmp} \neq 0$}{
			$res[j]=res_{tmp}$ \;
			break \;
		}
	}
	\caption{Robot kernel: code for one thread}
\end{algorithm}

In order to overlap computation time of GPU and CPU, an asynchronous version of the indicator function was written. Here the function is split in everything until the kernel launch and a wait function, which waits until the kernel finishes and recieves the result data. 

\begin{lstlisting}
int indicator2_async(const float* qs, const float* qe, int *res, 
					 const int N, const int offset, int &request);
int indicator2_async_wait(int request);
\end{lstlisting}

The implementation also allows overlapping of multiple requests, for example two calls of the launch function and after this the two corrsponding waiting calls. 
With this it is possible to use the full computation time of the GPU.

\newpage
\section{The PRM Solver}\label{solver}

- introduction

- dijkstra at the end makes almost no contribution to the whole time

	- can be parallelized, but this is again complicated
	
- focus on building the graph


\subsection{Storing the Graph}

Apart from the indicator function evaluation, the main problem in building the probabilistic roadmap is, that for each new node $q$ it have to be determined all possible neighbors. That is the set of all nodes $\tilde q$ of the graph, with $\norm{\tilde q - q} \le D$.
If no special order of the nodes is given, one has to calculate the norms for all nodes of the graph, which is rather time consuming.

Therefore a special indexing is used here. 
The nodes are stored in a vector, which is organized in blocks with fixed sizes. The blocks are referred to by ids which are stored in a map.

\begin{lstlisting}
struct block{	int pos;	 //! position of first vertex
	int num;	 //! current number of vertices stored
	block* next; //! if num==blocksize -> pointer to next block
};
\end{lstlisting}


\begin{lstlisting}
struct graph{    std::map<int,block*> map; //map for accessing blocks    std::vector<block> blocks;    std::vector<float> qstorage; //length ndof*N    int newblockpos;  //position of next new block    int blocknum;     //number of used blocks
    .
    .};
\end{lstlisting}

The key of an block is computed by the mapping
\begin{equation*}
	key(q) = \lfloor q(1)/H \rfloor
\end{equation*}
such that $H>0$ becomes a parameter to adjust the grid density.
This has to be chosen so large that enough nodes are stored in one block in order to have efficient memory access.
On the other side, the smaller it is, the less computations have to be done for the neighborhood requests.
For illustration the following pseudocode shows the insertion of a node.

\begin{algorithm}[H]
	\KwData{$q\in\R^d$}
	Compute key=key(q)\\ 
	\eIf{key exists in map}{
		block=map[key]\\ 
		\While{ block full }{
			block=block->next
		}
	}{
		insert new block at map[key]
	}
	Insert node in block
	\caption{Inserting a node}
\end{algorithm}



\subsection{Parallelization Models}

The parallelization is done with MPI. All processes store their own versions of the graph, which are hold up to date between each other.
Furthermore, it is assumed that every process has its own GPU.
The work of the single MPI processes could be parallelized further with OpenMP, but this has not been done here.
Instead only different approaches to distribute the work on several GPUs have been investigated.

\subsubsection*{Version 1} 

In the first approach, that was evaluated, every process generates new nodes independantly from each other.
Then the possible neighbours are determined and the connections, which have to be tested.
The indicator function is called and returnes the edges.
After this the graph must be synchronized on every processes, which leads to an alltoall communication.
As in this graph building does not need the edge data, it is sufficient to exchange only the nodes in this phase.

	
	\begin{center}
\begin{tikzpicture}[auto, node distance=0.5cm and 1.8cm]
	\node[block, minimum width=3cm] (prm) {
		\begin{tabular}{c}
		\textbf{PRMSolver 1}
		\end{tabular}
	};
	
	\node[frameless, below=of prm, minimum width=3cm] (space) {$\vdots$};
	
	\node[block, below=of space, minimum width=3cm] (prm2) {
		\begin{tabular}{c}
		\textbf{PRMSolver n}
		\end{tabular}
	};
	
	\node [block, right=of prm] (config) {
		\begin{tabular}{c}
		\textbf{Configpace 1}
		\end{tabular}
	};
	\node[frameless, below=of config] (space2) {$\vdots$};
	\node [block, below=of space2] (config2) {
		\begin{tabular}{c}
		\textbf{Configpace n}
		\end{tabular}
	};
	
	
	
	\node [block, right=of config] (gpu) {\textbf{GPU 1}};
	\node [block, right=of config2] (gpu2) {\textbf{GPU n}};
	
	
	\path[-latex',thick, shift left=1.0ex]	(prm) edge (config) 
								(config) edge (prm);
	\path[-,thick]					(config) edge (gpu);
	
	\path[-latex',thick, shift left=1.0ex]	(prm2) edge (config2) 
								(config2) edge (prm2) ;
	\path[-,thick]					(config2) edge (gpu2);
	
	
	\path[-latex',thick, shift left=1.0ex]	(prm) edge (space)
								(space) edge (prm)
								(prm2) edge (space)
								(space) edge (prm2) ;
	

\end{tikzpicture}
\end{center}
	

\subsubsection*{Version 2}
The second approach uses the fact, that by synchronizing the random seed, 
different processes can produce the same sequence of random numbers independently from each other.
By using this, every process can generate all new nodes and determine the connection data. 
Then the indicator function computation is splitted over their configuration space instances and the returned data shared afterwards with each other.
With this data, all graphs can be updated and it is guaranteed, that they are the same on each process.
The purpose of this version compared to the first one is, that less data has to be sent. 
Furthermore, in the first version it can occur, that the different generated nodes can result in very different counts of neighbours and therefore different loads on the GPUs.
Here, the distribution of the computation amount over the different GPUs can be chosen almost freely.


	
	\begin{center}
\begin{tikzpicture}[auto, node distance=0.5cm and 1.8cm]
	\node[block, minimum width=3cm] (prm) {
		\begin{tabular}{c}
		\textbf{PRMSolver 1}
		\end{tabular}
	};
	
	\node[frameless, below=of prm, minimum width=3cm] (space) {$\vdots$};
	
	\node[block, below=of space, minimum width=3cm] (prm2) {
		\begin{tabular}{c}
		\textbf{PRMSolver n}
		\end{tabular}
	};
	
	\node [block, right=of prm] (config) {
		\begin{tabular}{c}
		\textbf{Configpace 1}
		\end{tabular}
	};
	\node[frameless, below=of config] (space2) {$\vdots$};
	\node [block, below=of space2] (config2) {
		\begin{tabular}{c}
		\textbf{Configpace n}
		\end{tabular}
	};
	
	
	
	\node [block, right=of config] (gpu) {\textbf{GPU 1}};
	\node [block, right=of config2] (gpu2) {\textbf{GPU n}};
	
	
	\path[-latex',thick, shift left=1.5ex]	(prm) edge (config) ;
	\path[-,thick]					(config) edge (gpu);
	
	\path[-latex',thick, shift right=1.5ex]	(prm2) edge (config2) ;
	\path[-,thick]					(config2) edge (gpu2);
	
	
	\path[-latex',thick]				(config.west) edge  (prm.east) 
								(config.west) edge (space.east)
								(config.west) edge (prm2.east)
								(config2.west) edge  (prm.east) 
								(config2.west) edge (space.east)
								(config2.west) edge (prm2.east);

\end{tikzpicture}
\end{center}

\subsubsection*{Version 3}

The third version does a further optimization by using the asynchronous version of the indicator function.
Here, every process runs two workers overlapped. Here, in the time, when the first worker has generated his indicator function request and launched the kernel and is waiting until it has finished, the second worker updates the graph and sends his new request, and the other way round.
With this it is possible, that the computation time of the GPU is fully used, and overlapped with the communication.

\begin{center}
\begin{tikzpicture}
	\tikzset{mywidth/.style={minimum width=2.5cm},};
	\node[block, mywidth] (l1) {\textbf{Worker 1}};
	\node[frameless, mywidth, below=of l1, minimum height=1.5cm] (l2) {$\vdots$};
	\node[block, mywidth, below=of l2] (l3) 	{\begin{tabular}{c}
										generate\\ nodes, \\
										start kernel
									\end{tabular}};
	\node[frameless, mywidth, below=of l3, minimum height=2cm] (l6) {};
	\node[frameless, mywidth, below=of l6] (l7) {};
	\node[block, mywidth, below=of l7] (l11)	{\begin{tabular}{c}
										recieve\\ result, \\
										store nodes \\ 
										and edges
									\end{tabular}};
	\node[frameless, mywidth, below=of l11] (l12) {$\vdots$};
	
	
	\node[block, mywidth, right=of l1] (r1) {\textbf{Worker 2}};
	\node[frameless, mywidth, right=of l2, minimum height=1.5cm] (r2) {$\vdots$};
	\node[frameless, mywidth, right=of l3] (r3) {};
	\node[block, mywidth, right=of l6] (r6)	{\begin{tabular}{c}
										recieve\\ result, \\
										store nodes \\
										and edges
									\end{tabular}};
	\node[block, mywidth, right=of l7] (r7) 	{\begin{tabular}{c}
										generate\\ nodes, \\
										start kernel
									\end{tabular}};
	\node[frameless, mywidth, right=of l12] (r12) {$\vdots$};
	
	\node[frameless, left=of l1] (g1) {};
	\node[block, below=of g1, minimum height=14cm] (graph) {\rotatebox{90}{\textbf{Graph}}};
	
	
	%gpu column
	\tikzset{gpuwidth/.style={minimum width=0.8cm},};
	
	\node[block, right=2cm of r1, minimum width=2.5cm] {\textbf{GPU}};
	\node[frameless, right=2cm of r2, gpuwidth] (topa) {$\vdots$};
	\node[frameless, right=of topa, gpuwidth] (topb) {$\vdots$};
	\node[block2, below=0.7cm of topa, gpuwidth, minimum height=4.3cm] (stream1a) {\rotatebox{90}{kernel}};
	\node[block2, below=2.3cm of stream1a, gpuwidth, minimum height=4.2cm] (stream1b) {\rotatebox{90}{kernel}};
	\node[frameless, below=0.3cm of stream1b, gpuwidth] (bota) {$\vdots$};
	
	\node[block2, below=2.2cm of topb, gpuwidth, minimum height=7.6cm] (stream2) {\rotatebox{90}{kernel}};
	\node[frameless, right=of bota, gpuwidth] (botb) {$\vdots$};
	
	
	
	%EDGES
	
	\path[-latex',thick]	(graph.east |- l3.west) edge (l3.west)
					(l11.west) edge (graph.east |- l11.west);
	\path[-latex',thick]	(graph.east |- r7.west) edge (r7.west)
					(r6.west) edge (graph.east |- r6.west);
	\path[dotted,thick]	(l2) edge (l3)
					(l3) edge (l11)
					(l11) edge (l12)
					(r2) edge (r6)
					(r6) edge (r7)
					(r7) edge (r12);
	
	\path[-latex',thick]	(r6.east -| stream1b.west) edge (r6.east);
	\path[-latex',thick]	(r7.east) edge (r7.east -| stream1b.west);
	
	\path[-,thick]		(l3.east) edge (l3.east -| stream1a.west);
	\path[-latex',thick]	(stream1a.east |- l3.east) edge (l3.east -| stream2.west);
	\path[latex'-,thick]		(l11.east) edge (l11.east -| stream1b.west);
	\path[-,thick]		(stream1b.east |- l11.east) edge (l11.east -| stream2.west);
	
	
\end{tikzpicture}
\end{center}

\newpage
\section{Results}

\begin{wrapfigure}{r}{0.5\textwidth}\label{robotsolution}
	\centering
	\includegraphics[width=0.5\textwidth]{robotsolution.pdf}
	\caption{PRM generated collisionfree movement for a 4-axis robot}
\end{wrapfigure}

Tests have been made for a scenario with a robot with 4 joints. For creating and plotting the environment and the resulting trajectories, Matlab functions are provided.
Because of the dependancy on random numbers, the algorithm takes different amounts of time for different runs.
Therefore, 10 runs were made for each version and number of processes.
However, the different versions lead to a different average amount of GPU threads needed.
So, to be able to better compare how they scale, the time per number of GPU threads used as a quantity.
Table \ref{resulttable} shows the results.
One can see, that while the versions with node communication has a better time to GPU threads ratio, but leads to a greater amount of threads on average.
The versions with less communication however have better absolute times.
Furthermore, one sees the improvement from version 2 to version 3 from the asynchronous indicator function.

\ \\ 
\begin{table}[h]\label{resulttable}
\centering
\begin{tabular}{| c | c | r | r | r |}

\hline
version	&  processes/	& time (ms)	& GPU  		& time per 1e6  \\ 
		& GPUs		& 			& threads		& GPU threads (ms) \\ 
\hline
		& 1			& 1002		& 696413		& 1448	\\ 
1		& 2			& 763		& 838938		& 918	\\ 
		& 4			& 706		& 1113781	& 647	\\ 
\hline
		& 1			& 900		& 608172		& 1490	\\ 
2		& 2			& 647		& 608172		& 1070	\\ 
		& 4			& 568		& 608172		& 947	\\ 
\hline
		& 1			& 696		& 599847		& 1181	\\ 		
3		& 2			& 554		& 599847		& 951	\\ 
		& 4			& 500		& 599847		& 864	\\ 
\hline

\end{tabular}
\caption{Timing results for the parallelization versions from chapter \ref{solver}}
\end{table}


\bibliographystyle{alpha}
\begin{thebibliography}{999}
	\bibitem{prmlec} D. Burschka, Lecture Robot Motion Planning, source: http://robvis01.informatik.tu-muenchen.de/courses/wegtraj/index.html
	\bibitem{prm1} H. Choset, K. Lynch, S. Hutchinson, G. Kantor, W. Burgard, L. Kavraki and S. Thrun, Principles of Robot Motion: Theory, Algorithms, and Implementation, MIT Press, 2005
	\bibitem{prm2} S. M. LaValle, Planning Algorithms, Cambridge University Press, 2006
	\bibitem{robodyn} T. Buschmann, Skript zur Vorlesung: Roboterdynamik SS14, Lehrstuhl fr Angewandte Mechanik, TU Mnchen, 2014
	\bibitem{chung} K. Chung, Wenping Wang, Quick Collision Detection of Polytopes in Virtual Environments, Proceedings of the ACM Symposium on Virtual Reality Software and Technology (VRST 96), Mark Green (ed.), 1996
	\bibitem{ericson} C. Ericson, Real-Time Collision Detection, Elsevier, 2005
\end{thebibliography}

\end{document}


















